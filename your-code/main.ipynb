{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Prices in California with `LinearRegression()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will start inspect, analyze, visualize house price data from different districts in California, US. After having performed analysis, EDA and some feature engineering, you will build your own `LinearRegression()`  with `SkLearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure visualizations\n",
    "plt.style.use('default')  # Use default style instead of seaborn\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Inspection and Cleaning\n",
    "\n",
    "\n",
    "#### Import and Inspect your data\n",
    "\n",
    "Read the `housing.csv` file and make use of some methods to understand your data better. Below is an explanation of the features you are going to work with:\n",
    "\n",
    "1. **longitude:**  geographical coordinate, east to west position of district\n",
    "2. **latitude:**  geographical coordinate, north to south position of district\n",
    "3. **housing_median_age:** the median age of houses in district\n",
    "4. **total_rooms** Sum of all rooms in district\n",
    "5. **total_bedrooms** Sum of all bedrooms in district\n",
    "6. **population:** total population in district\n",
    "7. **households:** total households in district\n",
    "8. **median_income:** median household income in district \n",
    "9. **median_house_value:** median house value in district\n",
    "10. **ocean_proximity:** District´s proximity to the ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                            Non-Null Count  Dtype \n",
      "---  ------                                                                                            --------------  ----- \n",
      " 0    0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00  505 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 4.1+ KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "  0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00\n",
      "0   0.02731   0.00   7.070  0  0.4690  6.4210  78...                                             \n",
      "1   0.02729   0.00   7.070  0  0.4690  7.1850  61...                                             \n",
      "2   0.03237   0.00   2.180  0  0.4580  6.9980  45...                                             \n",
      "3   0.06905   0.00   2.180  0  0.4580  7.1470  54...                                             \n",
      "4   0.02985   0.00   2.180  0  0.4580  6.4300  58...                                             \n",
      "\n",
      "Basic statistics:\n",
      "       0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00\n",
      "count                                                 505                                             \n",
      "unique                                                505                                             \n",
      "top      0.02731   0.00   7.070  0  0.4690  6.4210  78...                                             \n",
      "freq                                                    1                                             \n",
      "\n",
      "Missing values:\n",
      "0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read the housing data\n",
    "housing_df = pd.read_csv('/Users/raneem/Desktop/SDA/ironhack/lab-ml-and-linear-regression/data/housing.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(housing_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(housing_df.head())\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(housing_df.describe())\n",
    "print(\"\\nMissing values:\")\n",
    "print(housing_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02731   0.00   7.070  0  0.4690  6.4210  78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02729   0.00   7.070  0  0.4690  7.1850  61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03237   0.00   2.180  0  0.4580  6.9980  45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06905   0.00   2.180  0  0.4580  7.1470  54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02985   0.00   2.180  0  0.4580  6.4300  58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.06263   0.00  11.930  0  0.5730  6.5930  69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.04527   0.00  11.930  0  0.5730  6.1200  76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.06076   0.00  11.930  0  0.5730  6.9760  91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.10959   0.00  11.930  0  0.5730  6.7940  89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.04741   0.00  11.930  0  0.5730  6.0300  80...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00\n",
       "0     0.02731   0.00   7.070  0  0.4690  6.4210  78...                                             \n",
       "1     0.02729   0.00   7.070  0  0.4690  7.1850  61...                                             \n",
       "2     0.03237   0.00   2.180  0  0.4580  6.9980  45...                                             \n",
       "3     0.06905   0.00   2.180  0  0.4580  7.1470  54...                                             \n",
       "4     0.02985   0.00   2.180  0  0.4580  6.4300  58...                                             \n",
       "..                                                 ...                                             \n",
       "500   0.06263   0.00  11.930  0  0.5730  6.5930  69...                                             \n",
       "501   0.04527   0.00  11.930  0  0.5730  6.1200  76...                                             \n",
       "502   0.06076   0.00  11.930  0  0.5730  6.9760  91...                                             \n",
       "503   0.10959   0.00  11.930  0  0.5730  6.7940  89...                                             \n",
       "504   0.04741   0.00  11.930  0  0.5730  6.0300  80...                                             \n",
       "\n",
       "[505 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms\n",
    "Make histograms of all your numeric columns in order to get a good understanding of the distribution of your data points. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create histograms for numeric columns\n",
    "numeric_columns = housing_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    housing_df[column].hist(bins=50)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create some features a tidy up our data\n",
    "\n",
    "1. Locate your NaN values and make a decision on how to handle them. Drop, fill with mean, or something else, it is entirely up to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column:\n",
      "0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00    0\n",
      "dtype: int64\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                            Non-Null Count  Dtype \n",
      "---  ------                                                                                            --------------  ----- \n",
      " 0    0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00  505 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 4.1+ KB\n",
      "None\n",
      "\n",
      "Basic statistics:\n",
      "       0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00\n",
      "count                                                 505                                             \n",
      "unique                                                505                                             \n",
      "top      0.02731   0.00   7.070  0  0.4690  6.4210  78...                                             \n",
      "freq                                                    1                                             \n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the dataset\n",
    "print(\"Number of NaN values in each column:\")\n",
    "print(housing_df.isnull().sum())\n",
    "\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(housing_df.info())\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(housing_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create three new columns by using simple arithmetic operations. Create one column with \"rooms per household\", one with \"population per household\",  and one with \"bedrooms per room\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'RM'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'RM'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create new feature columns using arithmetic operations\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m housing_df[\u001b[33m'\u001b[39m\u001b[33mrooms_per_household\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mhousing_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRM\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m / housing_df[\u001b[33m'\u001b[39m\u001b[33mHOUSEHOLDS\u001b[39m\u001b[33m'\u001b[39m] \n\u001b[32m      3\u001b[39m housing_df[\u001b[33m'\u001b[39m\u001b[33mpopulation_per_household\u001b[39m\u001b[33m'\u001b[39m] = housing_df[\u001b[33m'\u001b[39m\u001b[33mPOPULATION\u001b[39m\u001b[33m'\u001b[39m] / housing_df[\u001b[33m'\u001b[39m\u001b[33mHOUSEHOLDS\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m housing_df[\u001b[33m'\u001b[39m\u001b[33mbedrooms_per_room\u001b[39m\u001b[33m'\u001b[39m] = housing_df[\u001b[33m'\u001b[39m\u001b[33mBEDROOMS\u001b[39m\u001b[33m'\u001b[39m] / housing_df[\u001b[33m'\u001b[39m\u001b[33mRM\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'RM'"
     ]
    }
   ],
   "source": [
    "# Create new feature columns using arithmetic operations\n",
    "housing_df['rooms_per_household'] = housing_df['RM'] / housing_df['HOUSEHOLDS'] \n",
    "housing_df['population_per_household'] = housing_df['POPULATION'] / housing_df['HOUSEHOLDS']\n",
    "housing_df['bedrooms_per_room'] = housing_df['BEDROOMS'] / housing_df['RM']\n",
    "\n",
    "# Display the first few rows of the new columns\n",
    "print(\"\\nNew feature columns:\")\n",
    "print(housing_df[['rooms_per_household', 'population_per_household', 'bedrooms_per_room']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If you check the largest and smallest values of your \"rooms per houshold column\" you will see two outliers and two values that are just wrong. Drop the four values by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Exploratory Data Analysis\n",
    "\n",
    "\n",
    "\n",
    "#### Let's find out what factors have an influence on our predicting variable\n",
    "\n",
    "1. Let's check out the distribution of our \"median house value\". Visualize your results with 100 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check out what variables correlates the most with \"median house value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let's check out the distribution of the column that has the highest correlation to \"median house value\". Visualize your results with 100 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualize the \"median house value\" and \"median income\" in a jointplot (kind=\"reg\"). What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Make the same visualization as in the above, but, cahnge the kind parameter to \"kde\". What extra information does this type of visualization convey, that the one in the above does not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get schwifty with some EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new categorical column from the \"median income\" with the following quartiles `[0, 0.25, 0.5, 0.75, 0.95, 1]` and label them like this `[\"Low\", \"Below_Average\", \"Above_Average\", \"High\", \"Very High\"]` and name the column \"income_cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the Seaborn library, plot the count of your new column and set the `hue` to \"ocean_proximity\". What interesting things can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create two barplots where you set \"y=\"median_house_value\" on both, and the x is first \"income cat\" and then \"ocean_proximity\". How does these two graphs complement what you saw in the graph in your previous question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a pivoted dataframe where you have the values of the \"income cat\" column as indices and the values of the \"ocean_proximity\" column as columns. Also drop the \"ISLAND\" column that you'll get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Turn your pivoted dataframe into a heatmap. The heatmap should have annotations in integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Preparing your Data\n",
    "\n",
    "\n",
    "\n",
    "#### Splitting, Preparing and Engineering some Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let's drop the \"income_cat\" column as it has served its purpose already. We don't need for our model as we already have \"median income\".\n",
    "Not dropping \"incom cat\" will lead to multicolinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select your floating point columns and standardize your data by calculating the Z-score. You can apply the `stats.zscore()` method in a lambda function. Save your results to a variable called `z_scored`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Turn the only categorical columns into dummies. Be vary of the dummy trap, to avoid multicolinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save our predicting variable to `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Concatenate `z_scored` and `dummies` and drop the predicting variable. Save to the varible `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Machine Learning \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Train, Test, Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import `train_test_split` and split your data accordingly. Choose an appropriate test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Training our Model\n",
    "\n",
    "2. Build, fit and train a `LinearRegression` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In a scatterplot, visualize the y_train on your x-axis and your predictions on the y-axis. How does your training predictions look? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. From the sklearn metrics module, print the mean_squared_error and R^2-score. What does the metrics tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Predictions\n",
    "\n",
    "1. Now you are ready to make prediction on the test data. Do that and visualize your results in a new scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Print the mean_squared_error and R^2-score again. What has happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. There is another metric called Root mean squared error, Which is the square root of the MSE. Calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Questions 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a dataframe with two columns, one consisting of the y_test and one of your model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make a series of of your new dataframe, by calculating the predicted error in absolut numbers. Save this series to variable name `absolute_errors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If you take the mean of your series, you will get the mean absolute errors, which is another metric for Linear Regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Question 2 - Build a Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build, fit and train a `RandomForestRegressor` model. Do this by following the same staps that you followed when building your `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make prediction on the test data and evaluate you results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
